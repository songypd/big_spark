

hadoop回顾:
shuffle:MapTask  (write)   [SortShuffle]最终是合并成一个有序的文件
	Partitioner
		sort(P,K)
			combiner(reduce)
				mergeVlues(+-*/)    reduceByKey
				combinerVlues Seq	groupByKey
				
				
				hello  1
				hello  1
				hello  1
					1)  hello 3
					2)	hello (1,1,1) 
MR:有无combiner 2种shuffle写的实现行为


spark名词:
DAG:
	1,ShuffleMapStage --->  ShuffleMapTask   (包含shuffle-write)
	2,ResultStage     --->	ResultTask		

shuffle:
	HashShuffle
		不最终合并成一个文件,且不会有排序的过程.理论上,不会加大CPU的资源使用,实际中会让I/O小文件的弊端放大
	SortShuffle  最终合并成一个文件,以下就是3种shufflewrite
		1,ByPassSortMegre
			读取记录,直接准备分区数量的小文件
			最终把小文件链接成一个大文件
			分区数限制,200个
		2,SortShuffle
			只按分区排序
			缓冲区Map
		3,UnsafeSort...堆外
灵活的胖子
[[计算过程当中,shuffleWrite是根据开发人员使用的不同算子来选择合适的shufflewrite]]



RDD;
RDD(Resilient Distributed Datasets),弹性分布式数据集， 是分布式内存的一个抽象概念，RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，
只能通过在其他RDD执行确定的转换操作（如map、join和group by）而创建,然而这些限制使得实现容错的开销很低。对开发者而言，RDD可以看作是Spark的一个对象，
它本身运行于内存中，如读文件是一个RDD，对文件计算是一个RDD，结果集也是一个RDD ，不同的分片、 数据之间的依赖 、key-value类型的map数据都可以看做RDD。

弹性分布式数据集（RDD，Resilient Distributed Datasets），它具备像MapReduce等数据流模型的容错特性，并且允许开发人员在大型集群上执行基于内存的计算。
现有的数据流系统对两种应用的处理并不高效：一是迭代式算法，这在图应用和机器学习领域很常见；二是交互式数据挖掘工具。这两种情况下，
将数据保存在内存中能够极大地提高性能。为了有效地实现容错，RDD提供了一种高度受限的共享内存，即RDD是只读的，并且只能通过其他RDD上的批量操作来创建。
尽管如此，RDD仍然足以表示很多类型的计算，包括MapReduce和专用的迭代编程模型（如Pregel）等

RDD是只读的、分区记录的集合。RDD只能基于在稳定物理存储中的数据集和其他已有的RDD上执行确定性操作来创建。这些确定性操作称之为转换，
如map、filter、groupBy、join（转换不是程开发人员在RDD上执行的操作）

RDD不需要物化。RDD含有如何从其他RDD衍生（即计算）出本RDD的相关信息（即Lineage），据此可以从物理存储的数据计算出相应的RDD分区

RDD作为数据结构，本质上是一个只读的分区记录集合。一个RDD可以包含多个分区，每个分区就是一个dataset片段。RDD可以相互依赖。
如果RDD的每个分区最多只能被一个Child RDD的一个分区使用，则称之为narrow dependency；若多个Child RDD分区都可以依赖，则称之为wide dependency。
不同的操作依据其特性，可能会产生不同的依赖。例如map操作会产生narrow dependency，而join操作则产生wide dependency。


